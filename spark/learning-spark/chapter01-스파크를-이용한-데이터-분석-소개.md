
Chapter01. 스파크를 이용한 데이터 분석 소개
==


아파치 스파크란 무엇인가?
--
  
아파츼 스파크는 범용적이면서도 빠른 속도로 작업을 수행할 수 있도록 설계한 클러스터용 연산 플랫폼이다.
  
속도라는 면에서 스파크는 다양한 연산 모델을 효과적으로 지원하는, 익시 유명한 맵 리듀스(MapReduce) 모델을 대화형(interactive) 명령어 쿼리(query)나 
스트리밍(streaming) 처리 등이 가능하도록 확장하였다.
  
스파크가 속도를 높이기 위하여 제공하는 중요한 기능 중 하나는 연산을 메모리에서 수행하는 기능이지만, 설령 복잡한 프로그램을 메모리가 아닌 디스크에서 돌리더라도 
맵 리듀스보다는 더욱 뛰어난 성능을 보여준다.
  
  
통합된 구성
--
  
스파크 프로젝트는 밀접하여 연동된 여러 개의 컴포넌트로 구성되어 있다.

![Image of Spark Components](https://www.tutorialspoint.com/apache_spark/images/components_of_spark.jpg)
 
  
#### 스파크 코어
스파크 코어는 작업 스케줄링, 메모리 관리, 장애 복구, 저장 장치와의 연동 등등 기본적인 기능들로 구성된다. 스파크 코어는 탄력적인 분산 데이터세트(__RDD__ /Resilient Distributed Dataset)를 
정의하는 API의 기반이 되며, 이것이 주된 스파크 프로그래밍 추상화의 구조이다. __RDD__ 는 여러 컴퓨터 노드에 흩어져 있으며 병렬 처리될 수 있는 아이템들의 모음을 표현한다. 
  
#### 스파크 SQL
스파크 SQL은 정형 데이터를 처리하기 위한 스파크의 패키지이다. 스파크 SQL은 단순히 SQL 인터페이스를 제공하는 것 이상으로 SQL과 복잡한 분석 작업을 서로 연결
할 수 있도록 지원한다.
  
#### 스파크 스트리밍
스파크 스트리밍은 실시간 데이터 스트림을 처리 가능하게 해 주는 스파크의 컴포넌트이다.
  
#### MLlib
스파크는 MLlib 라는 일반적인 머신 러닝 기능들을 갖고 있는 라이브러리와 함께 배포된다.
  
#### 그래프X
그래프X는 그래프를 다루기 위한 라이브러리이며, 그래프 병렬 연산을 수행한다.
